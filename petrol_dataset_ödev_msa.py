# -*- coding: utf-8 -*-
"""Petrol Dataset Ödev MSA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16j7txzTN0hKVSs4cpL4eijnp14w-U2qC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import csv

from plotly.offline import init_notebook_mode, iplot, plot
import plotly as py
init_notebook_mode(connected=True)
import plotly.graph_objs as go

ts = pd.read_excel("/content/train_test.xlsx")

ts.describe()

ts.columns

ts.rename(columns={"Data" : "Work Time"}, inplace = True)
ts["Work Time"] = pd.to_datetime(ts["Work Time"], errors='ignore')
ts.sort_values("Work Time", inplace=True)
ts.set_index("Work Time", inplace=True)

ts.head()

ts.info()

print(ts.isnull().sum(), "\n\n")

ts.dropna(subset = ['Y1'], inplace = True)

print(ts.isnull().sum())

ts[-2:]

counter = 0
for i in ts.index:
    if i[-2:] != "00":
        counter +=1
        print(i)
        print(counter)

if counter == 0:
    print("Saatlik veri almamis olan baska bir index bulunmamistir.")

column_list = ts.columns
for i in column_list:
    print("Column Name:", i, ", Total Number: ", len(ts[i]), ", Unique Number: ", len(ts[i].unique()))

ts[ts.duplicated(subset = ["Y1"])]

expected_D_list = ['2014-05-20 12:00']

index_D_list = []

counter = 0

for i in range(133,10898):
    counter +=1
    if counter == 24:
        expected_D_list.append(ts.iloc[i].name)
        counter = 0


for i in ts[ts['D'].notna()].index:
    index_D_list.append(i)


a = [ element for element in expected_D_list if element not in index_D_list]
b = [ element for element in index_D_list if element not in expected_D_list]
print(len(a))
print(len(b))

print("expected_D_list'de bulunup verisetinde olmayan veriler: ",a)
print("-------------------------------------------------------------------------")
print("Verisetinde bulunup expected_D_list'de olmayan veriler: ",b)

ts[(ts["Y1"] > ts["Y2"])]

ts[(ts["Y3"] < ts["Y4"])]

ts[(ts["Y4"] > ts["Y5"])]

ts[(ts["Y5"] < ts["Y6"])]

ts.info()

temp = ts.copy()

for i in ts[ts["Y1"] < 0.8].index:
  print(i)

for i in ts[ts["Y4"] < 5].index:
  print(i)

for i in ts.loc[(ts.Y1.shift(1) > (ts.Y1 + 1.9)) & (ts.Y1.shift(-1) > (ts.Y1 + 1.9))].index:
  print(i)

for i in ts.loc[(ts.Y1.shift(1) > (ts.Y1 + 1.9)) & (ts.Y1.shift(-1) > (ts.Y1 + 1.9))].index:
  print(ts.loc[i])

ts.drop(ts.loc[(ts.index >= '2015-03-25 13:00') & (ts.index <= '2015-03-26 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-11-18 13:00') & (ts.index <= '2014-11-29 12:00')].index, inplace=True)

ts.drop(ts.loc[(ts.index >= '2014-07-25 13:00') & (ts.index <= '2014-07-26 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-08-17 13:00') & (ts.index <= '2014-08-18 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-09-12 13:00') & (ts.index <= '2014-09-13 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-12-16 13:00') & (ts.index <= '2014-12-18 12:00')].index, inplace=True)

ts = ts.copy()
ts["Y1"] = ts["Y1"].rolling(24).mean()
ts["Y2"] = ts["Y2"].rolling(24).mean()
ts["Y3"] = ts["Y3"].rolling(24).mean()
ts["Y4"] = ts["Y4"].rolling(24).mean()
ts["Y5"] = ts["Y5"].rolling(24).mean()
ts["Y6"] = ts["Y6"].rolling(24).mean()

ts[(ts["U1"] < 700) | (ts["U1"] > 753) ]

ts[(ts["O2"] < 5000) | (ts["O2"] > 19000)]

ts.drop(ts.loc[(ts.index >= '2015-01-27 13:00') & (ts.index <= '2015-01-28 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-12-18 13:00') & (ts.index <= '2014-12-19 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-05-26 13:00') & (ts.index <= '2014-05-27 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-05-28 13:00') & (ts.index <= '2014-05-29 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-07-27 13:00') & (ts.index <= '2014-07-28 12:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index >= '2014-10-04 13:00') & (ts.index <= '2014-10-05 12:00')].index, inplace=True)

ts.info()

ts = ts[ ['Y1', 'Y2', 'E1', 'E2', 'A1', 'Y3', 'Y4', 'Y5', 'Y6', 'U1', 'U2','D']]

ts.info()

index_array = np.array(ts[ts["D"].notna() == True].index)
value_D_array = ts["D"].unique()[1:]
ts_index_len = len(ts[ts["D"].isnull() == False])
ts.drop(["D", "E1", "E2"], axis = 1, inplace = True)

ts.info()

counter1 = 0
counter2 = 0
mean_Y1_list = []
mean_Y2_list = []
mean_Y3_list = []
mean_Y4_list = []
mean_Y5_list = []
mean_Y6_list = []
mean_A1_list = []
mean_U1_list = []
mean_U2_list = []

type(mean_Y1_list)

for i in range(int(len(ts.index))):
    counter2 +=24
    mean_Y1_list.append(ts["Y1"][counter1:counter2].values.mean())
    mean_Y2_list.append(ts["Y2"][counter1:counter2].values.mean())
    mean_Y3_list.append(ts["Y3"][counter1:counter2].values.mean())
    mean_Y4_list.append(ts["Y4"][counter1:counter2].values.mean())
    mean_Y5_list.append(ts["Y5"][counter1:counter2].values.mean())
    mean_Y6_list.append(ts["Y6"][counter1:counter2].values.mean())
    mean_A1_list.append(ts["A1"][counter1:counter2].values.mean())
    mean_U1_list.append(ts["U1"][counter1:counter2].values.mean())
    mean_U2_list.append(ts["U2"][counter1:counter2].values.mean())
    counter1 +=24

ts.drop(ts.loc[(ts.index == '2014-05-15 00:00')].index, inplace=True)
ts.drop(ts.loc[(ts.index == '2014-05-20 12:00')].index, inplace=True)

ts.isnull().any()

mean_Y1_list = np.array(mean_Y1_list)
mean_Y2_list = np.array(mean_Y2_list)
mean_Y3_list = np.array(mean_Y3_list)
mean_Y4_list = np.array(mean_Y4_list)
mean_Y5_list = np.array(mean_Y5_list)
mean_Y6_list = np.array(mean_Y6_list)
mean_A1_list = np.array(mean_A1_list)
mean_U1_list = np.array(mean_U1_list)
mean_U2_list = np.array(mean_U2_list)

ts["mean_Y1"] = mean_Y1_list
ts["mean_Y2"] = mean_Y2_list
ts["mean_Y3"] = mean_Y3_list
ts["mean_Y4"] = mean_Y4_list
ts["mean_Y5"] = mean_Y5_list
ts["mean_Y6"] = mean_Y6_list
ts["mean_A1"] = mean_A1_list
ts["mean_U1"] = mean_U1_list
ts["mean_U2"] = mean_U2_list

ts.drop(['Y1', 'Y2', 'A1', 'Y3', 'Y4', 'Y5', 'Y6', 'U1', 'U2'], axis = 1, inplace = True)
ts.drop(ts.loc[(ts.index >= ts.index[ts_index_len]) & (ts.index <= ts.index[-1])].index, inplace=True)
ts["D"] = value_D_array
ts.set_index([index_array], inplace=True)

ts

ts[ts["D"] < 35].head(10)

ts.drop(ts[ts.index == '2014-12-30 12:00'].index, inplace=True)
ts.drop(ts[ts.index == '2015-01-15 12:00'].index, inplace=True)
ts.drop(ts[ts.index == '2015-01-20 12:00'].index, inplace=True)
ts.drop(ts[ts.index == '2015-01-21 12:00'].index, inplace=True)
ts.drop(ts[ts.index == '2015-01-23 12:00'].index, inplace=True)

from pathlib import Path
filepath = Path('/content/drive/MyDrive/Datathon/yarisma_veriseti/ml_dataset.csv')

ts.to_csv(filepath, encoding = "utf-8")

"""# Makine Ogrenmesi Modelinin Olusturulmasi"""

# Import Machine Learning Libraries

from sklearn.naive_bayes import GaussianNB


from sklearn.cross_decomposition import PLSRegression
from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, StackingRegressor, VotingRegressor
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.kernel_ridge import KernelRidge
from sklearn.linear_model import LogisticRegression, SGDRegressor,BayesianRidge, LassoLars, ARDRegression, PassiveAggressiveRegressor,TheilSenRegressor, LinearRegression, Ridge, ARDRegression, PoissonRegressor, TweedieRegressor, GammaRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR, NuSVR, LinearSVR



from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score

from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error
from math import sqrt

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

y = ts.D.values
x_data = ts.drop(["D"],axis=1)

# Train Test Split

x_train, x_test, y_train, y_test = train_test_split(x_data,y, test_size = 0.15,random_state = 65)
print("x_train",len(x_train))
print("x_test",len(x_test))
print("y_train",len(y_train))
print("y_test",len(y_test))

train_scaled = scaler.fit_transform(x_train)
test_scaled = scaler.transform(x_test)

ts.isnull().any()

ts

classifier = [SVR(C=50, gamma=0.1)]


for item in classifier:
    clf = item
    clf.fit(train_scaled, y_train)
    scores = cross_val_score(clf, train_scaled, y_train, cv = 5, scoring = "r2")


    mse = mean_squared_error(y_train, clf.predict(train_scaled))
    mae = mean_absolute_error(y_train, clf.predict(train_scaled))
    mape = mean_absolute_percentage_error(y_train, clf.predict(train_scaled))

    test_mse = mean_squared_error(y_test, clf.predict(test_scaled))
    test_mae = mean_absolute_error(y_test, clf.predict(test_scaled))
    test_mape = mean_absolute_percentage_error(y_test, clf.predict(test_scaled))

    print("train mse = ",mse," & train mae = ",mae," & train rmse = ", sqrt(mse),  " & train mape = ", mape, "\n")
    print("test mse = ",test_mse," & test mae = ",test_mae," & test rmse = ", sqrt(test_mse), " & test mape = ", test_mape, "\n\n" )

    print("Test accuracy: %.3f%% " % (clf.score(test_scaled, y_test)*100))
    print("R2 Scores: ", scores)

# Model Prediction ve Orijinal Test Grafigi
new_df = pd.DataFrame()
new_df['y_test'] = y_test
new_df["y_pred"] = clf.predict(test_scaled)
plt.figure(figsize=(12,8))
new_df["y_pred"].plot(color = "red")
new_df["y_test"].plot(color = "blue")
plt.ylabel("D Değerleri")
plt.xlabel("Indexler")
plt.title("Orijinal D Değerleri ve Tahmin Edilen D Değerleri")
plt.legend()
plt.grid()
plt.show()

error_list = ["MSE","MAE","RMSE","MAPE"]
error_values = [1.4269847293493618 , 0.9765151100906923 , 1.1945646610164566, 0.0192996899491003]

def show_values(axs, orient="v", space=.01):
    def _single(ax):
        if orient == "v":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() / 2
                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)
                value = '{:.3f}'.format(p.get_height())
                ax.text(_x, _y, value, ha="center")
        elif orient == "h":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() + float(space)
                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)
                value = '{:.3f}'.format(p.get_width())
                ax.text(_x, _y, value, ha="left")

    if isinstance(axs, np.ndarray):
        for idx, ax in np.ndenumerate(axs):
            _single(ax)
    else:
        _single(axs)



fig, ax = plt.subplots(figsize=(27,8))
fig.suptitle('Modelin Error Sonuçları', fontsize=26)
sns.set_theme(style="whitegrid")
tips = sns.load_dataset("tips")
ax = sns.barplot(x = error_list, y=error_values, data=tips)
plt.grid(False)
show_values(ax)

"""# **Prediction Veri Analizi**"""

prediction = pd.read_csv("/content/prediction.csv")
prediction = prediction[ ['Work Time','Y1', 'Y2', 'A1', 'Y3', 'Y4', 'Y5', 'Y6', 'U1', 'U2']]

prediction.set_index("Work Time", inplace=True)

print(prediction.isnull().sum(), "\n\n")


prediction.dropna(subset = ['Y1'], inplace = True)
print("-----------\n\n")

print(prediction.isnull().sum())

if ( (prediction.index[0][11:] == "14:00") | (prediction.index[0][11:] == "15:00") | (prediction.index[0][11:] == "16:00") | (prediction.index[0][11:] == "17:00") | (prediction.index[0][11:] == "18:00") | (prediction.index[0][11:] == "19:00") | (prediction.index[0][11:] == "20:00") | (prediction.index[0][11:] == "21:00") | (prediction.index[0][11:] == "22:00") | (prediction.index[0][11:] == "23:00")):

    prediction.drop(prediction.loc[(prediction.index >= prediction.index[0]) & (prediction.index <= (prediction.index[9][:11] + "12:00"))].index, inplace=True)

elif((prediction.index[0][11:] == "13:00")):
    pass
else:
    prediction.drop(prediction.loc[(prediction.index >= prediction.index[0]) & (prediction.index <= (prediction.index[0][:11] + "12:00"))].index, inplace=True)



if ((prediction.index[-1][11:] == "23:00") | (prediction.index[-1][11:] == "22:00") | (prediction.index[-1][11:] == "21:00") | (prediction.index[-1][11:] == "20:00") | (prediction.index[-1][11:] == "19:00") | (prediction.index[-1][11:] == "18:00") |  (prediction.index[-1][11:] == "17:00") | (prediction.index[-1][11:] == "16:00") | (prediction.index[-1][11:] == "15:00") | (prediction.index[-1][11:] == "14:00") | (prediction.index[-1][11:] == "13:00")):

    prediction.drop(prediction.loc[(prediction.index >= (prediction.index[-1][:11] + "13:00")) & (prediction.index <= prediction.index[-1])].index, inplace=True)

elif ( (prediction.index[-1][11:] == "12:00") ):
    pass


else:
    prediction.drop(prediction.loc[(prediction.index >= (prediction.index[-13][:11] + "13:00")) & (prediction.index <= prediction.index[-1])].index, inplace=True)

index_array = []
counter1 = 0
counter2 = 0
mean_Y1_list = []
mean_Y2_list = []
mean_Y3_list = []
mean_Y4_list = []
mean_Y5_list = []
mean_Y6_list = []
mean_A1_list = []
mean_U1_list = []
mean_U2_list = []

for i in range(1, int(len(prediction.index )) + 1):

    if i % 24 == 0:
        index_array.append(prediction.index[i-1])
    counter2 +=24
    mean_Y1_list.append(prediction["Y1"][counter1:counter2].values.mean())
    mean_Y2_list.append(prediction["Y2"][counter1:counter2].values.mean())
    mean_Y3_list.append(prediction["Y3"][counter1:counter2].values.mean())
    mean_Y4_list.append(prediction["Y4"][counter1:counter2].values.mean())
    mean_Y5_list.append(prediction["Y5"][counter1:counter2].values.mean())
    mean_Y6_list.append(prediction["Y6"][counter1:counter2].values.mean())
    mean_A1_list.append(prediction["A1"][counter1:counter2].values.mean())
    mean_U1_list.append(prediction["U1"][counter1:counter2].values.mean())
    mean_U2_list.append(prediction["U2"][counter1:counter2].values.mean())
    counter1 +=24


mean_Y1_list = np.array(mean_Y1_list)
mean_Y2_list = np.array(mean_Y2_list)
mean_Y3_list = np.array(mean_Y3_list)
mean_Y4_list = np.array(mean_Y4_list)
mean_Y5_list = np.array(mean_Y5_list)
mean_Y6_list = np.array(mean_Y6_list)
mean_A1_list = np.array(mean_A1_list)
mean_U1_list = np.array(mean_U1_list)
mean_U2_list = np.array(mean_U2_list)


prediction["mean_Y1"] = mean_Y1_list
prediction["mean_Y2"] = mean_Y2_list
prediction["mean_Y3"] = mean_Y3_list
prediction["mean_Y4"] = mean_Y4_list
prediction["mean_Y5"] = mean_Y5_list
prediction["mean_Y6"] = mean_Y6_list
prediction["mean_A1"] = mean_A1_list
prediction["mean_U1"] = mean_U1_list
prediction["mean_U2"] = mean_U2_list

prediction.head()

prediction.drop(['Y1', 'Y2', 'A1', 'Y3', 'Y4', 'Y5', 'Y6', 'U1', 'U2'], axis = 1, inplace = True)
prediction.drop(prediction.loc[(prediction.index >= prediction.index[int(len(prediction.index) / 24)]) & (prediction.index <= prediction.index[-1])].index, inplace=True)
prediction.set_index([index_array], inplace=True)

# Prediction For ML
pred_scaled = scaler.fit_transform(prediction)

new_df = pd.DataFrame()
new_df.index = prediction.index
new_df["D"] = clf.predict(pred_scaled)

new_df